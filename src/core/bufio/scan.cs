// Copyright 2013 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.
namespace go;

using bytes = bytes_package;
using errors = errors_package;
using io = io_package;
using utf8 = unicode.utf8_package;
using unicode;

partial class bufio_package {

// Scanner provides a convenient interface for reading data such as
// a file of newline-delimited lines of text. Successive calls to
// the [Scanner.Scan] method will step through the 'tokens' of a file, skipping
// the bytes between the tokens. The specification of a token is
// defined by a split function of type [SplitFunc]; the default split
// function breaks the input into lines with line termination stripped. [Scanner.Split]
// functions are defined in this package for scanning a file into
// lines, bytes, UTF-8-encoded runes, and space-delimited words. The
// client may instead provide a custom split function.
//
// Scanning stops unrecoverably at EOF, the first I/O error, or a token too
// large to fit in the [Scanner.Buffer]. When a scan stops, the reader may have
// advanced arbitrarily far past the last token. Programs that need more
// control over error handling or large tokens, or must run sequential scans
// on a reader, should use [bufio.Reader] instead.
[GoType] partial struct Scanner {
    internal io_package.Reader r; // The reader provided by the client.
    internal SplitFunc split; // The function to split the tokens.
    internal nint maxTokenSize;      // Maximum size of a token; modified by tests.
    internal slice<byte> token; // Last token returned by split.
    internal slice<byte> buf; // Buffer used as argument to split.
    internal nint start;      // First non-processed byte in buf.
    internal nint end;      // End of data in buf.
    internal error err;     // Sticky error.
    internal nint empties;      // Count of successive empty tokens.
    internal bool scanCalled;      // Scan has been called; buffer is in use.
    internal bool done;      // Scan has finished.
}

public delegate (nint advance, slice<byte> token, error err) SplitFunc(slice<byte> data, bool atEOF);

// Errors returned by Scanner.
public static error ErrTooLong = errors.New("bufio.Scanner: token too long"u8);

public static error ErrNegativeAdvance = errors.New("bufio.Scanner: SplitFunc returns negative advance count"u8);

public static error ErrAdvanceTooFar = errors.New("bufio.Scanner: SplitFunc returns advance count beyond input"u8);

public static error ErrBadReadCount = errors.New("bufio.Scanner: Read returned impossible count"u8);

public static readonly UntypedInt MaxScanTokenSize = /* 64 * 1024 */ 65536;
internal static readonly UntypedInt startBufSize = 4096; // Size of initial allocation for buffer.

// NewScanner returns a new [Scanner] to read from r.
// The split function defaults to [ScanLines].
public static ж<Scanner> NewScanner(io.Reader r) {
    return Ꮡ(new Scanner(
        r: r,
        split: ScanLines,
        maxTokenSize: MaxScanTokenSize
    ));
}

// Err returns the first non-EOF error that was encountered by the [Scanner].
[GoRecv] public static error Err(this ref Scanner s) {
    if (AreEqual(s.err, io.EOF)) {
        return default!;
    }
    return s.err;
}

// Bytes returns the most recent token generated by a call to [Scanner.Scan].
// The underlying array may point to data that will be overwritten
// by a subsequent call to Scan. It does no allocation.
[GoRecv] public static slice<byte> Bytes(this ref Scanner s) {
    return s.token;
}

// Text returns the most recent token generated by a call to [Scanner.Scan]
// as a newly allocated string holding its bytes.
[GoRecv] public static @string Text(this ref Scanner s) {
    return ((@string)s.token);
}

// ErrFinalToken is a special sentinel error value. It is intended to be
// returned by a Split function to indicate that the scanning should stop
// with no error. If the token being delivered with this error is not nil,
// the token is the last token.
//
// The value is useful to stop processing early or when it is necessary to
// deliver a final empty token (which is different from a nil token).
// One could achieve the same behavior with a custom error value but
// providing one here is tidier.
// See the emptyFinalToken example for a use of this value.
public static error ErrFinalToken = errors.New("final token"u8);

// Scan advances the [Scanner] to the next token, which will then be
// available through the [Scanner.Bytes] or [Scanner.Text] method. It returns false when
// there are no more tokens, either by reaching the end of the input or an error.
// After Scan returns false, the [Scanner.Err] method will return any error that
// occurred during scanning, except that if it was [io.EOF], [Scanner.Err]
// will return nil.
// Scan panics if the split function returns too many empty
// tokens without advancing the input. This is a common error mode for
// scanners.
[GoRecv] public static bool Scan(this ref Scanner s) {
    if (s.done) {
        return false;
    }
    s.scanCalled = true;
    // Loop until we have a token.
    while (ᐧ) {
        // See if we can get a token with what we already have.
        // If we've run out of data but have an error, give the split function
        // a chance to recover any remaining, possibly empty token.
        if (s.end > s.start || s.err != default!) {
            nint advance = s.split(s.buf[(int)(s.start)..(int)(s.end)], s.err != default!);
            var token = s.split(s.buf[(int)(s.start)..(int)(s.end)], s.err != default!);
            var err = s.split(s.buf[(int)(s.start)..(int)(s.end)], s.err != default!);
            if (err != default!) {
                if (AreEqual(err, ErrFinalToken)) {
                    s.token = token;
                    s.done = true;
                    // When token is not nil, it means the scanning stops
                    // with a trailing token, and thus the return value
                    // should be true to indicate the existence of the token.
                    return token != default!;
                }
                s.setErr(err);
                return false;
            }
            if (!s.advance(advance)) {
                return false;
            }
            s.token = token;
            if (token != default!) {
                if (s.err == default! || advance > 0){
                    s.empties = 0;
                } else {
                    // Returning tokens not advancing input at EOF.
                    s.empties++;
                    if (s.empties > maxConsecutiveEmptyReads) {
                        throw panic("bufio.Scan: too many empty tokens without progressing");
                    }
                }
                return true;
            }
        }
        // We cannot generate a token with what we are holding.
        // If we've already hit EOF or an I/O error, we are done.
        if (s.err != default!) {
            // Shut it down.
            s.start = 0;
            s.end = 0;
            return false;
        }
        // Must read more data.
        // First, shift data to beginning of buffer if there's lots of empty space
        // or space is needed.
        if (s.start > 0 && (s.end == len(s.buf) || s.start > len(s.buf) / 2)) {
            copy(s.buf, s.buf[(int)(s.start)..(int)(s.end)]);
            s.end -= s.start;
            s.start = 0;
        }
        // Is the buffer full? If so, resize.
        if (s.end == len(s.buf)) {
            // Guarantee no overflow in the multiplication below.
            const nint maxInt = /* int(^uint(0) >> 1) */ 9223372036854775807;
            if (len(s.buf) >= s.maxTokenSize || len(s.buf) > maxInt / 2) {
                s.setErr(ErrTooLong);
                return false;
            }
            nint newSize = len(s.buf) * 2;
            if (newSize == 0) {
                newSize = startBufSize;
            }
            newSize = min(newSize, s.maxTokenSize);
            var newBuf = new slice<byte>(newSize);
            copy(newBuf, s.buf[(int)(s.start)..(int)(s.end)]);
            s.buf = newBuf;
            s.end -= s.start;
            s.start = 0;
        }
        // Finally we can read some input. Make sure we don't get stuck with
        // a misbehaving Reader. Officially we don't need to do this, but let's
        // be extra careful: Scanner is for safe, simple jobs.
        for (nint loop = 0; ᐧ ; ) {
            var (n, err) = s.r.Read(s.buf[(int)(s.end)..(int)(len(s.buf))]);
            if (n < 0 || len(s.buf) - s.end < n) {
                s.setErr(ErrBadReadCount);
                break;
            }
            s.end += n;
            if (err != default!) {
                s.setErr(err);
                break;
            }
            if (n > 0) {
                s.empties = 0;
                break;
            }
            loop++;
            if (loop > maxConsecutiveEmptyReads) {
                s.setErr(io.ErrNoProgress);
                break;
            }
        }
    }
}

// advance consumes n bytes of the buffer. It reports whether the advance was legal.
[GoRecv] internal static bool advance(this ref Scanner s, nint n) {
    if (n < 0) {
        s.setErr(ErrNegativeAdvance);
        return false;
    }
    if (n > s.end - s.start) {
        s.setErr(ErrAdvanceTooFar);
        return false;
    }
    s.start += n;
    return true;
}

// setErr records the first error encountered.
[GoRecv] internal static void setErr(this ref Scanner s, error err) {
    if (s.err == default! || AreEqual(s.err, io.EOF)) {
        s.err = err;
    }
}

// Buffer sets the initial buffer to use when scanning
// and the maximum size of buffer that may be allocated during scanning.
// The maximum token size must be less than the larger of max and cap(buf).
// If max <= cap(buf), [Scanner.Scan] will use this buffer only and do no allocation.
//
// By default, [Scanner.Scan] uses an internal buffer and sets the
// maximum token size to [MaxScanTokenSize].
//
// Buffer panics if it is called after scanning has started.
[GoRecv] public static void Buffer(this ref Scanner s, slice<byte> buf, nint max) {
    if (s.scanCalled) {
        throw panic("Buffer called after Scan");
    }
    s.buf = buf[0..(int)(cap(buf))];
    s.maxTokenSize = max;
}

// Split sets the split function for the [Scanner].
// The default split function is [ScanLines].
//
// Split panics if it is called after scanning has started.
[GoRecv] public static void Split(this ref Scanner s, SplitFunc split) {
    if (s.scanCalled) {
        throw panic("Split called after Scan");
    }
    s.split = split;
}

// Split functions

// ScanBytes is a split function for a [Scanner] that returns each byte as a token.
public static (nint advance, slice<byte> token, error err) ScanBytes(slice<byte> data, bool atEOF) {
    nint advance = default!;
    slice<byte> token = default!;
    error err = default!;

    if (atEOF && len(data) == 0) {
        return (0, default!, default!);
    }
    return (1, data[0..1], default!);
}

internal static slice<byte> errorRune = slice<byte>(((@string)utf8.RuneError));

// ScanRunes is a split function for a [Scanner] that returns each
// UTF-8-encoded rune as a token. The sequence of runes returned is
// equivalent to that from a range loop over the input as a string, which
// means that erroneous UTF-8 encodings translate to U+FFFD = "\xef\xbf\xbd".
// Because of the Scan interface, this makes it impossible for the client to
// distinguish correctly encoded replacement runes from encoding errors.
public static (nint advance, slice<byte> token, error err) ScanRunes(slice<byte> data, bool atEOF) {
    nint advance = default!;
    slice<byte> token = default!;
    error err = default!;

    if (atEOF && len(data) == 0) {
        return (0, default!, default!);
    }
    // Fast path 1: ASCII.
    if (data[0] < utf8.RuneSelf) {
        return (1, data[0..1], default!);
    }
    // Fast path 2: Correct UTF-8 decode without error.
    var (_, width) = utf8.DecodeRune(data);
    if (width > 1) {
        // It's a valid encoding. Width cannot be one for a correctly encoded
        // non-ASCII rune.
        return (width, data[0..(int)(width)], default!);
    }
    // We know it's an error: we have width==1 and implicitly r==utf8.RuneError.
    // Is the error because there wasn't a full rune to be decoded?
    // FullRune distinguishes correctly between erroneous and incomplete encodings.
    if (!atEOF && !utf8.FullRune(data)) {
        // Incomplete; get more bytes.
        return (0, default!, default!);
    }
    // We have a real UTF-8 encoding error. Return a properly encoded error rune
    // but advance only one byte. This matches the behavior of a range loop over
    // an incorrectly encoded string.
    return (1, errorRune, default!);
}

// dropCR drops a terminal \r from the data.
internal static slice<byte> dropCR(slice<byte> data) {
    if (len(data) > 0 && data[len(data) - 1] == (rune)'\r') {
        return data[0..(int)(len(data) - 1)];
    }
    return data;
}

// ScanLines is a split function for a [Scanner] that returns each line of
// text, stripped of any trailing end-of-line marker. The returned line may
// be empty. The end-of-line marker is one optional carriage return followed
// by one mandatory newline. In regular expression notation, it is `\r?\n`.
// The last non-empty line of input will be returned even if it has no
// newline.
public static (nint advance, slice<byte> token, error err) ScanLines(slice<byte> data, bool atEOF) {
    nint advance = default!;
    slice<byte> token = default!;
    error err = default!;

    if (atEOF && len(data) == 0) {
        return (0, default!, default!);
    }
    {
        nint i = bytes.IndexByte(data, (rune)'\n'); if (i >= 0) {
            // We have a full newline-terminated line.
            return (i + 1, dropCR(data[0..(int)(i)]), default!);
        }
    }
    // If we're at EOF, we have a final, non-terminated line. Return it.
    if (atEOF) {
        return (len(data), dropCR(data), default!);
    }
    // Request more data.
    return (0, default!, default!);
}

// isSpace reports whether the character is a Unicode white space character.
// We avoid dependency on the unicode package, but check validity of the implementation
// in the tests.
internal static bool isSpace(rune r) {
    if (r <= (rune)'\u00FF') {
        // Obvious ASCII ones: \t through \r plus space. Plus two Latin-1 oddballs.
        switch (r) {
        case (rune)' ' or (rune)'\t' or (rune)'\n' or (rune)'\v' or (rune)'\f' or (rune)'\r': {
            return true;
        }
        case (rune)'\u0085' or (rune)'\u00A0': {
            return true;
        }}

        return false;
    }
    // High-valued ones.
    if ((rune)'\u2000' <= r && r <= (rune)'\u200a') {
        return true;
    }
    switch (r) {
    case (rune)'\u1680' or (rune)'\u2028' or (rune)'\u2029' or (rune)'\u202f' or (rune)'\u205f' or (rune)'\u3000': {
        return true;
    }}

    return false;
}

// ScanWords is a split function for a [Scanner] that returns each
// space-separated word of text, with surrounding spaces deleted. It will
// never return an empty string. The definition of space is set by
// unicode.IsSpace.
public static (nint advance, slice<byte> token, error err) ScanWords(slice<byte> data, bool atEOF) {
    nint advance = default!;
    slice<byte> token = default!;
    error err = default!;

    // Skip leading spaces.
    nint start = 0;
    for (nint width = 0; start < len(data); start += width) {
        rune rΔ1 = default!;
        (, width) = utf8.DecodeRune(data[(int)(start)..]);
        if (!isSpace(rΔ1)) {
            break;
        }
    }
    // Scan until space, marking end of word.
    for (nint width = 0;nint i = start; i < len(data); i += width) {
        rune r = default!;
        (r, width) = utf8.DecodeRune(data[(int)(i)..]);
        if (isSpace(r)) {
            return (i + width, data[(int)(start)..(int)(i)], default!);
        }
    }
    // If we're at EOF, we have a final, non-empty, non-terminated word. Return it.
    if (atEOF && len(data) > start) {
        return (len(data), data[(int)(start)..], default!);
    }
    // Request more data.
    return (start, default!, default!);
}

} // end bufio_package
